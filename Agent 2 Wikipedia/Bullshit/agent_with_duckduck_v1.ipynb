{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "68fca549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the data available for the model\n",
    "metal_data = {\n",
    "    \"unit\":\"gram\",\n",
    "    \"currency\": \"USD\",\n",
    "    \"prices\": {\n",
    "        \"gold\": 88.1553,\n",
    "        \"silver\": 1.0523,\n",
    "        \"platinum\": 32.169,\n",
    "        \"palladium\": 35.8252,\n",
    "        \"copper\": 0.0098,\n",
    "        \"aluminum\": 0.0026,\n",
    "        \"lead\": 0.0021,\n",
    "        \"nickel\": 0.0159,\n",
    "        \"zinc\": 0.0031,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aecf1480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tool\\ndef search_duckduckgo(query: str) -> str:\\n\\n    #Performs a DuckDuckGo search using a JSON endpoint and returns the first result snippet.\\n\\n    try:\\n        url = \"https://api.duckduckgo.com/\"\\n        params = {\"q\": query, \"format\": \"json\", \"no_html\": 1, \"skip_disambig\": 1}\\n        resp = requests.get(url, params=params, timeout=10)\\n        data = resp.json()\\n\\n        if \"AbstractText\" in data and data[\"AbstractText\"]:\\n            return data[\"AbstractText\"]\\n        elif data.get(\"RelatedTopics\"):\\n            for topic in data[\"RelatedTopics\"]:\\n                if isinstance(topic, dict) and topic.get(\"Text\"):\\n                    return topic[\"Text\"]\\n        return \"No relevant results found.\"\\n    except Exception as e:\\n        return f\"Search error: {e}\"\\nimport requests'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "\n",
    "# Define the tools for the agent to use, it is necessary to specify that each function is a tool\n",
    "@tool\n",
    "def get_metal_price(metal_name: str) -> str:\n",
    "    \"\"\"Fetches the current per gram in USD price of the specified metal.\n",
    "\n",
    "    Args:\n",
    "        metal_name : The name of the metal (e.g., 'gold', 'silver', 'platinum').\n",
    "\n",
    "    Returns:\n",
    "        float: The current price of the metal in dollars per gram.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the specified metal is not found in the data source.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metal_name = metal_name.lower().strip()\n",
    "        prices = metal_data[\"prices\"]\n",
    "        currency = metal_data[\"currency\"]\n",
    "        unit=metal_data[\"unit\"]\n",
    "        if metal_name not in prices:\n",
    "            raise KeyError(\n",
    "                f\"Metal {metal_name} not found. Available metals: {', '.join(metal_data['prices'].keys())}\"\n",
    "            )\n",
    "        price=prices[metal_name]\n",
    "        return f\"The current price of {metal_name} is {price} {currency} per {unit}.\"\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching metal price: {str(e)}\")\n",
    "    \n",
    "@tool    \n",
    "def get_currency_exchange(base: str, target: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the exchange rate from base currency to target currency.\n",
    "\n",
    "    Args:\n",
    "        base (str): The base currency (e.g., 'USD').\n",
    "        target (str): The target currency (e.g., 'EUR').\n",
    "\n",
    "    Returns:\n",
    "        str: A human-readable string showing the exchange rate,\n",
    "             or an error message if the pair is not found.\n",
    "    \"\"\"\n",
    "    fake_rates = {\n",
    "        (\"usd\", \"eur\"): 0.8,\n",
    "        (\"eur\", \"usd\"): 1.8,\n",
    "        (\"usd\", \"gbp\"): 0.7\n",
    "    }\n",
    "    rate = fake_rates.get((base.lower(), target.lower()))\n",
    "    if rate is None:\n",
    "        return f\"No exchange rate found for {base.upper()} to {target.upper()}\"\n",
    "    return  f\"{base.upper()} = {rate} {target.upper()}\"\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for a summary related to the query.\"\"\"\n",
    "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{query.replace(' ', '_')}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get(\"extract\", \"No summary found.\")\n",
    "    else:\n",
    "        return \"No relevant results found.\"\n",
    "\n",
    "\"\"\"@tool\n",
    "def search_duckduckgo(query: str) -> str:\n",
    "    \n",
    "    #Performs a DuckDuckGo search using a JSON endpoint and returns the first result snippet.\n",
    "    \n",
    "    try:\n",
    "        url = \"https://api.duckduckgo.com/\"\n",
    "        params = {\"q\": query, \"format\": \"json\", \"no_html\": 1, \"skip_disambig\": 1}\n",
    "        resp = requests.get(url, params=params, timeout=10)\n",
    "        data = resp.json()\n",
    "\n",
    "        if \"AbstractText\" in data and data[\"AbstractText\"]:\n",
    "            return data[\"AbstractText\"]\n",
    "        elif data.get(\"RelatedTopics\"):\n",
    "            for topic in data[\"RelatedTopics\"]:\n",
    "                if isinstance(topic, dict) and topic.get(\"Text\"):\n",
    "                    return topic[\"Text\"]\n",
    "        return \"No relevant results found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {e}\"\n",
    "import requests\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059acbf",
   "metadata": {},
   "source": [
    "En este bloque definimos la herramienta get_metal_price con el decorador @tool, igual que en el ejemplo de RAGAS\n",
    "docs.ragas.io\n",
    ". Esta función recibe un nombre de metal y devuelve su precio simulado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d39daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Instanciamos el modelo LLM local usando Ollama (Llama 3.2)\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",   # Usamos el modelo Llama 3.2 local\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Vinculamos nuestra herramienta al LLM\n",
    "tools = [get_metal_price,get_currency_exchange,search_wikipedia]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm_with_tools,\n",
    "    tools=[get_metal_price, get_currency_exchange,search_wikipedia],\n",
    "    prompt=\"\"\"\n",
    "You are a ReAct agent.\n",
    "\n",
    "For questions about metal prices like \"What is the price of METAL in CUR?\":\n",
    "1) Call `get_metal_price` with the metal name (e.g., \"gold\").\n",
    "2) Then call `get_currency_exchange` with base='USD' and target=CUR.\n",
    "3) Combine both results in a final response with the price converted.\n",
    "\n",
    "For general knowledge or factual questions (e.g., \"Who is the president of France?\"):\n",
    "1) Call `search_wikipedia` with a well-formed query.\n",
    "2) Use the result to respond clearly and concisely.\n",
    "\n",
    "\n",
    "When you call a tool, your final response must be exactly and only the content returned by the tool. Do not rephrase, summarize or add any additional information. Do not use your own knowledge.\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa2366",
   "metadata": {},
   "source": [
    "Aquí creamos el objeto ChatOllama de LangChain usando el modelo Llama3.2 local python.langchain.com, y vinculamos la lista de herramientas (sólo get_metal_price) con .bind_tools python.langchain.com. Esto permite que el modelo invoque la herramienta cuando sea necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ae8959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import END\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# 1) State\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# 2) Nodes\n",
    "tool_functions = [get_metal_price,get_currency_exchange,search_wikipedia]\n",
    "tool_node = ToolNode(tool_functions)\n",
    "\n",
    "def assistant(state: GraphState):\n",
    "    # 1) Pasar todo el historial al agente ReAct\n",
    "    result = agent.invoke({\"messages\": state[\"messages\"]})\n",
    "    \n",
    "    # 2) Extraer la lista de nuevos mensajes\n",
    "    new_msgs = result[\"messages\"]\n",
    "    \n",
    "    # 3) Devolver el historial completo concatenado\n",
    "    return {\"messages\": state[\"messages\"] + new_msgs}\n",
    "\n",
    "def should_continue(state: GraphState):\n",
    "    last = state[\"messages\"][-1]\n",
    "\n",
    "    # 1) Si es un dict y contiene tool_calls\n",
    "    if isinstance(last, dict) and last.get(\"tool_calls\"):\n",
    "        return \"tools\"\n",
    "\n",
    "    # 2) Si es un objeto con atributo tool_calls (p.ej. AIMessage)\n",
    "    tc = getattr(last, \"tool_calls\", None)\n",
    "    if tc:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6dd42ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Define a new graph for the agent\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "builder.add_edge(START, \"assistant\")\n",
    "\n",
    "# Making a conditional edge\n",
    "# should_continue will determine which node is called next.\n",
    "builder.add_conditional_edges(\"assistant\", should_continue, {\"tools\", END})\n",
    "\n",
    "# Making a normal edge from `tools` to `agent`.\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# Compile and display the graph for a visual overview\n",
    "react_graph = builder.compile()\n",
    "#display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5252284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.messages import AIMessage,ToolMessage,HumanMessage\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "def normalize_args(args):\n",
    "    return {k.lower(): str(v).lower() for k, v in args.items()}\n",
    "\n",
    "def fix_tool_calls_for_openai_format(messages):\n",
    "    final_messages = []\n",
    "    tool_message_buffer = {}\n",
    "    used_tool_call_ids = set()\n",
    "\n",
    "    # Indexar ToolMessages por tool_call_id\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            tool_message_buffer[msg.tool_call_id] = msg\n",
    "\n",
    "    for msg in messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            final_messages.append(msg)\n",
    "\n",
    "        elif isinstance(msg, AIMessage) and msg.tool_calls and len(msg.tool_calls) > 1:\n",
    "            for tool_call in msg.tool_calls:\n",
    "                # Normalizar los args aquí\n",
    "                norm_args = normalize_args(tool_call[\"args\"])\n",
    "\n",
    "                new_msg = deepcopy(msg)\n",
    "                new_msg.tool_calls = [{\n",
    "                    \"name\": tool_call[\"name\"],\n",
    "                    \"args\": norm_args,\n",
    "                    \"id\": tool_call.get(\"id\", f\"call_{uuid.uuid4().hex[:24]}\"),\n",
    "                    \"type\": \"tool_call\"\n",
    "                }]\n",
    "                new_msg.additional_kwargs[\"tool_calls\"] = [{\n",
    "                    \"id\": tool_call.get(\"id\", f\"call_{uuid.uuid4().hex[:24]}\"),\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_call[\"name\"],\n",
    "                        \"arguments\": json.dumps(norm_args)\n",
    "                    }\n",
    "                }]\n",
    "                final_messages.append(new_msg)\n",
    "\n",
    "                tool_msg = tool_message_buffer.get(tool_call[\"id\"])\n",
    "                if tool_msg:\n",
    "                    final_messages.append(tool_msg)\n",
    "                    used_tool_call_ids.add(tool_call[\"id\"])\n",
    "\n",
    "        elif isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "            tool_call = msg.tool_calls[0]\n",
    "            norm_args = normalize_args(tool_call[\"args\"])\n",
    "\n",
    "            msg.tool_calls[0][\"args\"] = norm_args\n",
    "            msg.additional_kwargs[\"tool_calls\"] = [{\n",
    "                \"id\": tool_call.get(\"id\", f\"call_{uuid.uuid4().hex[:24]}\"),\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool_call[\"name\"],\n",
    "                    \"arguments\": json.dumps(norm_args)\n",
    "                }\n",
    "            }]\n",
    "            final_messages.append(msg)\n",
    "\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            final_messages.append(msg)\n",
    "\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            if msg.tool_call_id not in used_tool_call_ids:\n",
    "                final_messages.append(msg)\n",
    "\n",
    "    return final_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "487d8a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'messages = {\"messages\":[{\"role\":\"user\",\"content\":\"What is the price of gold in EUR?\"}]}\\nresult = react_graph.invoke(messages)\\n\\n# Mostrar el historial de mensajes resultante\\nfor msg in result[\"messages\"]:\\n    print(msg)'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de ejecución del agente con una pregunta del usuario\n",
    "\"\"\"messages = {\"messages\":[{\"role\":\"user\",\"content\":\"What is the price of gold in EUR?\"}]}\n",
    "result = react_graph.invoke(messages)\n",
    "\n",
    "# Mostrar el historial de mensajes resultante\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f22ddbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_messages=fix_tool_calls_for_openai_format(result[\"messages\"])\n",
    "#fixed_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "029f1764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='What is the name of the president of France?' additional_kwargs={} response_metadata={} id='6ba22744-eba8-4665-b9a7-9f514835a1f4'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-05-28T18:14:58.6696809Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11027147300, 'load_duration': 24875900, 'prompt_eval_count': 581, 'prompt_eval_duration': 9491806600, 'eval_count': 20, 'eval_duration': 1507745600, 'model_name': 'llama3.2'} id='run--56702508-ddce-490a-992e-a513fdc5b5a1-0' tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'President of France'}, 'id': '20dff9e0-e8d5-4bc1-9de6-b634d67f0206', 'type': 'tool_call'}] usage_metadata={'input_tokens': 581, 'output_tokens': 20, 'total_tokens': 601}\n",
      "content='The president of France, officially the president of the French Republic, is the executive head of state of France, and the commander-in-chief of the French Armed Forces. As the presidency is the supreme magistracy of the country, the position is the highest office in France. The powers, functions and duties of prior presidential offices, in addition to their relation with the prime minister and government of France, have over time differed with the various constitutional documents since the Second Republic.' name='search_wikipedia' id='64feb3b0-1be4-41a3-8b99-a31a3e40c3f6' tool_call_id='20dff9e0-e8d5-4bc1-9de6-b634d67f0206'\n",
      "content='The current president of France is Emmanuel Macron.' additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-05-28T18:15:03.1126562Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4300303100, 'load_duration': 19458500, 'prompt_eval_count': 354, 'prompt_eval_duration': 3547522600, 'eval_count': 10, 'eval_duration': 731765000, 'model_name': 'llama3.2'} id='run--10629f26-45e7-4292-ab1a-84e5494aec47-0' usage_metadata={'input_tokens': 354, 'output_tokens': 10, 'total_tokens': 364}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de ejecución del agente con una pregunta del usuario\n",
    "messages = {\"messages\":[{\"role\":\"user\",\"content\":\"What is the name of the president of France?\"}]}\n",
    "result = react_graph.invoke(messages)\n",
    "\n",
    "# Mostrar el historial de mensajes resultante\n",
    "for msg in result[\"messages\"]:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "968d2e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Who is the president of France?', additional_kwargs={}, response_metadata={}, id='9a964459-3796-46fd-a1f4-b287dbb17f13'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '55ba4744-cc9d-4bab-acfe-dbf106c4d3c0', 'type': 'function', 'function': {'name': 'search_wikipedia', 'arguments': '{\"query\": \"president of france\"}'}}]}, response_metadata={'model': 'llama3.2', 'created_at': '2025-05-28T18:13:57.5508677Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12944868300, 'load_duration': 23603500, 'prompt_eval_count': 578, 'prompt_eval_duration': 11427244100, 'eval_count': 20, 'eval_duration': 1492437400, 'model_name': 'llama3.2'}, id='run--9871165b-d22e-43d1-a987-ded1dad772f0-0', tool_calls=[{'name': 'search_wikipedia', 'args': {'query': 'president of france'}, 'id': '55ba4744-cc9d-4bab-acfe-dbf106c4d3c0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 20, 'total_tokens': 598}),\n",
       " ToolMessage(content='The president of France, officially the president of the French Republic, is the executive head of state of France, and the commander-in-chief of the French Armed Forces. As the presidency is the supreme magistracy of the country, the position is the highest office in France. The powers, functions and duties of prior presidential offices, in addition to their relation with the prime minister and government of France, have over time differed with the various constitutional documents since the Second Republic.', name='search_wikipedia', id='46fd7048-f1a0-411a-bd32-439d7ccb6ba7', tool_call_id='55ba4744-cc9d-4bab-acfe-dbf106c4d3c0'),\n",
       " AIMessage(content='The current president of France is Emmanuel Macron.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-05-28T18:14:01.8350848Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4170749900, 'load_duration': 18313000, 'prompt_eval_count': 351, 'prompt_eval_duration': 3463275000, 'eval_count': 10, 'eval_duration': 687557300, 'model_name': 'llama3.2'}, id='run--f13fe053-6646-4a1a-92c9-8ffb9b7960d6-0', usage_metadata={'input_tokens': 351, 'output_tokens': 10, 'total_tokens': 361})]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_messages=fix_tool_calls_for_openai_format(result[\"messages\"])\n",
    "fixed_messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
