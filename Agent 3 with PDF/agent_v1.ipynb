{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4bc20f",
   "metadata": {},
   "source": [
    "# Agent 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ca5bb",
   "metadata": {},
   "source": [
    "Define a dictionary that maps metal names to their corresponding Yahoo Finance ticker symbols for price retrieval using the yfinance library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps common metal names to their corresponding Yahoo Finance symbols.\n",
    "METAL_SYMBOLS = {\n",
    "    \"gold\": \"GC=F\",\n",
    "    \"silver\": \"SI=F\",\n",
    "    \"platinum\": \"PL=F\",\n",
    "    \"palladium\": \"PA=F\",\n",
    "    \"copper\": \"HG=F\",\n",
    "    \"aluminum\": None,   \n",
    "    \"nickel\": None,      \n",
    "    \"zinc\": None,      \n",
    "    \"lead\": None       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313027fa",
   "metadata": {},
   "source": [
    "Define three tools for the new agent: one extracts metal information from a PDF, another retrieves recent metal prices from Yahoo Finance, and the third fetches a general description of the metal from Wikipedia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import yfinance as yf\n",
    "from utils import *\n",
    "\n",
    "# Define the tools for the agent to use, it is necessary to specify that each function is a tool\n",
    "@tool\n",
    "def get_metal_info(metal_name: str, path: str = \"Metals Description 2023.pdf\") -> str:\n",
    "    \"\"\"\n",
    "    Returns the description, uses, and price of a specified metal from the PDF.\n",
    "\n",
    "    Args:\n",
    "        metal_name (str): Name of the metal to search for.\n",
    "        path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: Information about the metal or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not path:\n",
    "            path = \"Metals Description 2023.pdf\"\n",
    "        doc = fitz.open(path)\n",
    "        full_text = \"\"\n",
    "        for page in doc:\n",
    "            full_text += page.get_text()\n",
    "        doc.close()\n",
    "\n",
    "        pattern = re.compile(\n",
    "            r\"(?P<name>[A-Za-z]+)\\s*Description:\\s*(?P<desc>.*?)\\s*Industrial Uses:\\s*(?P<uses>.*?)\\s*2023 Price:\\s*(?P<price>[\\d\\.]+)\\s*USD per gram\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "\n",
    "        metals = {}\n",
    "        for match in pattern.finditer(full_text):\n",
    "            name = match.group(\"name\").strip().lower()\n",
    "            metals[name] = {\n",
    "                \"description\": match.group(\"desc\").strip(),\n",
    "                \"uses\": match.group(\"uses\").strip(),\n",
    "                \"price\": match.group(\"price\").strip()\n",
    "            }\n",
    "\n",
    "        key = metal_name.strip().lower()\n",
    "        if key not in metals:\n",
    "            return f\"No information found for metal '{metal_name}'.\"\n",
    "\n",
    "        info = metals[key]\n",
    "        return (\n",
    "            f\"{metal_name.capitalize()}\\n\"\n",
    "            f\"- Description: {info['description']}\\n\"\n",
    "            f\"- Industrial Uses: {info['uses']}\\n\"\n",
    "            f\"- 2023 Price: {info['price']} USD/gram\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error processing PDF: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_metal_price_yfinance(metal_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets the latest closing price of a metal from Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        metal_name (str): One of 'gold', 'silver', 'platinum', 'palladium', 'copper'.\n",
    "\n",
    "    Returns:\n",
    "        str: Price with date, or error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        symbol = METAL_SYMBOLS.get(metal_name.lower())\n",
    "        if not symbol:\n",
    "            return f\"Metal '{metal_name}' not supported.\"\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        hist = ticker.history(period=\"5d\")\n",
    "        if hist.empty:\n",
    "            return f\"No price data available for {metal_name}.\"\n",
    "        \n",
    "        last_price = hist[\"Close\"].iloc[-1]\n",
    "        last_date = hist.index[-1].date()\n",
    "\n",
    "        return f\"The latest {metal_name} price was {last_price:.2f} USD per ounce on {last_date}.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving {metal_name} price: {e}\"\n",
    "    \n",
    "@tool\n",
    "def describe_metal(metal_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Tries to fetch a description of the metal from Wikipedia.\n",
    "    Falls back from 'metal_name (metal)' to just 'metal_name' if necessary.\n",
    "    \"\"\"\n",
    "    def fetch_summary(title: str):\n",
    "        url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{title.replace(' ', '_')}\"\n",
    "        response = requests.get(url, timeout=10,verify=False)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data.get(\"extract\", \"No summary found.\")\n",
    "    \n",
    "    try:\n",
    "        return fetch_summary(f\"{metal_name} (metal)\")\n",
    "    except requests.HTTPError:\n",
    "        try:\n",
    "            return fetch_summary(metal_name)\n",
    "        except Exception as e2:\n",
    "            return f\"Error fetching metal description: {e2}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching metal description: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6f388",
   "metadata": {},
   "source": [
    "Initialise a local LLM and create a ReAct agent specialised in metal-related queries. The agent uses three tools to retrieve technical information from a PDF, current market prices from Yahoo Finance, or general descriptions from Wikipedia, following a structured reasoning prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create de model\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",   \n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Link the tools to the LLM\n",
    "tools = [get_metal_info,describe_metal,get_metal_price_yfinance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm_with_tools,\n",
    "    tools=tools,\n",
    "    prompt= \"\"\"\n",
    "\n",
    "You are a ReAct agent specialized in answering questions about metals.\n",
    "You have access to the following tools:\n",
    "\n",
    "1. `get_metal_info(metal_name)`: Retrieves a technical description, industrial uses, and the 2023 reference price for a specific metal from a local PDF document.\n",
    "2. `get_metal_price_yfinance(metal_name)`: Retrieves the most recent market price (USD/ounce) of common metals like gold, silver, platinum, palladium, and copper.\n",
    "3. `describe_metal(metal_name)`: Provides a general encyclopedic description of a metal from Wikipedia.\n",
    "\n",
    "You must follow this step-by-step reasoning:\n",
    "\n",
    "1. First, identify exactly which tool matches the user's request.\n",
    "    - Use `get_metal_info` if the question refers to \"the document\", \"technical data\", \"description\", \"uses\", or \"2023 price\".\n",
    "    - Use `get_metal_price_yfinance` if the question is about current or market price.\n",
    "    - Use `describe_metal` only if the user is asking for general knowledge.\n",
    "\n",
    "2. Call the tool.\n",
    "\n",
    "3. Then summarize or quote the tool output explicitly in your final answer. Do not invent information. Do not skip this step.\n",
    "\n",
    "Your answers must be clear and informative. Do not write anything until the tool has responded. Always base your answers on the tool output.\n",
    "\"\"\"\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b413ddf",
   "metadata": {},
   "source": [
    "Set up the agent's graph structure with a conditional transition: the assistant node runs first, and the graph ends only if the last AI message does not contain a tool call. Otherwise, the assistant continues reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain.schema.messages import AIMessage,ToolMessage,HumanMessage\n",
    "\n",
    "# 1) State\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "def assistant(state: GraphState):\n",
    "    result = agent.invoke({\"messages\": state[\"messages\"]})\n",
    "    new_msgs = result[\"messages\"]\n",
    "    return {\"messages\": state[\"messages\"] + new_msgs}\n",
    "\n",
    "#Building the graph for the agent\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "\n",
    "builder.add_edge(START, \"assistant\")                         \n",
    "builder.add_edge(\"assistant\", END)            \n",
    "\n",
    "react_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a5056",
   "metadata": {},
   "source": [
    "Execute a predefined list of test questions through the agent, then format each conversation into RAGAS-compatible samples and store the raw message histories for later inspection or evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39973e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eguzk\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\eguzk\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\eguzk\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\eguzk\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\eguzk\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\eguzk\\anaconda3\\envs\\tfm_env\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'en.wikipedia.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample questions about metal descriptions and prices\n",
    "test_questions = [\n",
    "    (\"Describe gold\"),\n",
    "    (\"What does the document say about copper?\"),\n",
    "    (\"What does the PDF say about the industrial uses of copper?\"),\n",
    "    (\"Can you give me the description and price of silver from the document?\"),\n",
    "    (\"What does the document mention about palladium's applications?\"),\n",
    "    (\"Whatâ€™s the current market price of gold?\"),\n",
    "    (\"How much is silver trading at today?\"),\n",
    "    (\"Can you check the latest price of copper and describe it?\"),\n",
    "    (\"What is platinum and what are its main characteristics?\"),\n",
    "    (\"What's the technical description of silver\")\n",
    "]\n",
    "\n",
    "ragas_samples = []  # RAGAS-ready samples\n",
    "conv = []           # Full message traces\n",
    "\n",
    "for q in test_questions:\n",
    "    result = react_graph.invoke({\"messages\": [HumanMessage(content=q)]})\n",
    "    messages = fix_tool_calls_for_openai_format(result[\"messages\"])\n",
    "    conv.append(messages)\n",
    "    sample = lc_to_ragas_sample(messages)\n",
    "    ragas_samples.append(sample.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e14110",
   "metadata": {},
   "source": [
    "Extract key elements from each conversation, including the question, tool call, tool output, and final response and save both the full RAGAS samples and a simplified version of the data for evaluation or manual inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee995dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "minimal_data = []\n",
    "\n",
    "for conversation in conv:\n",
    "    # Initialise fields to store key elements\n",
    "    question = None\n",
    "    last_response = None\n",
    "    tool_calls = None\n",
    "    tool_message = None\n",
    "\n",
    "    for msg in conversation:\n",
    "        if isinstance(msg, HumanMessage) and question is None:\n",
    "            # Take the first user message as the question\n",
    "            question = msg.content\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            # Save tool call info if present, otherwise keep the response\n",
    "            if \"tool_calls\" in msg.additional_kwargs:\n",
    "                tool_calls = msg.additional_kwargs[\"tool_calls\"][0][\"function\"]\n",
    "            else:\n",
    "                last_response = msg.content\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            # Save the tool's output message\n",
    "            tool_message = msg.content\n",
    "\n",
    "    # Append entry only if question and final response are available\n",
    "    if question and last_response:\n",
    "        minimal_data.append({\n",
    "            \"question\": question,\n",
    "            \"tool_calls\": tool_calls,\n",
    "            \"tool message\": tool_message,\n",
    "            \"response\": last_response\n",
    "        })\n",
    "\n",
    "# Save full RAGAS samples and minimal conversation data\n",
    "with open(\"Results/ragas_sample_v1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(ragas_samples, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(\"Results/conversation_v1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(minimal_data, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748be96f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EVALUATION\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a76da6b",
   "metadata": {},
   "source": [
    "Load the previously saved RAGAS-formatted samples from a JSON file and reconstruct them as SingleTurnSample objects for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaaf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "import json\n",
    "\n",
    "# Load saved RAGAS-formatted samples\n",
    "with open(\"Results/ragas_sample_v1.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Rebuild list of SingleTurnSample objects\n",
    "samples = [SingleTurnSample(**d) for d in data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804889c",
   "metadata": {},
   "source": [
    "Evaluate all single-turn samples using RAGAS metrics, context precision, faithfulness, and answer relevancy, then store the results in a DataFrame and export them as a CSV file for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eguzk\\AppData\\Local\\Temp\\ipykernel_13244\\3627059898.py:10: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  local_llm = Ollama(model=\"mistral\", temperature=0, timeout=60000)\n",
      "C:\\Users\\eguzk\\AppData\\Local\\Temp\\ipykernel_13244\\3627059898.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.metrics import (LLMContextPrecisionWithoutReference,Faithfulness,ResponseRelevancy,)\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "local_llm = Ollama(model=\"mistral\", temperature=0, timeout=60000)\n",
    "wrapped_llm = LangchainLLMWrapper(local_llm)\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "ragas_embeddings = LangchainEmbeddingsWrapper(hf_embeddings)\n",
    "\n",
    "# Metrics\n",
    "metrics = {\n",
    "    \"context_precision_no_ref\": LLMContextPrecisionWithoutReference(llm=wrapped_llm),\n",
    "    \"faithfulness\": Faithfulness(llm=wrapped_llm),\n",
    "    \"answer_relevancy\": ResponseRelevancy(llm=wrapped_llm, embeddings=ragas_embeddings),\n",
    "}\n",
    "\n",
    "results = asyncio.run(evaluate_all_safe(samples,metrics))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.to_csv(\"Results/results_v1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
